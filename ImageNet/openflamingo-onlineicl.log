nohup: ignoring input
/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().
  warnings.warn(_BETA_TRANSFORMS_WARNING)
/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().
  warnings.warn(_BETA_TRANSFORMS_WARNING)
Traceback (most recent call last):
  File "/data/chy/online/ImageNet/main.py", line 51, in <module>
    model, image_processor, tokenizer = create_model_and_transforms(
  File "/data/chy/online/open_flamingo_v2/open_flamingo/src/factory.py", line 73, in create_model_and_transforms
    lang_encoder = AutoModelForCausalLM.from_pretrained(
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/transformers/models/auto/auto_factory.py", line 553, in from_pretrained
    model_class = get_class_from_dynamic_module(
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/transformers/dynamic_module_utils.py", line 552, in get_class_from_dynamic_module
    return get_class_in_module(class_name, final_module, force_reload=force_download)
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/transformers/dynamic_module_utils.py", line 249, in get_class_in_module
    module_spec.loader.exec_module(module)
  File "<frozen importlib._bootstrap_external>", line 850, in exec_module
  File "<frozen importlib._bootstrap>", line 228, in _call_with_frames_removed
  File "/home/chy63/.cache/huggingface/modules/transformers_modules/modeling_mpt.py", line 18, in <module>
    from .hf_prefixlm_converter import add_bidirectional_mask_if_missing, convert_hf_causal_lm_to_prefix_lm
  File "/home/chy63/.cache/huggingface/modules/transformers_modules/hf_prefixlm_converter.py", line 15, in <module>
    from transformers.models.bloom.modeling_bloom import _expand_mask as _expand_mask_bloom
ImportError: cannot import name '_expand_mask' from 'transformers.models.bloom.modeling_bloom' (/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/transformers/models/bloom/modeling_bloom.py)
