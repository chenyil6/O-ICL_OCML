nohup: ignoring input
/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torchvision/datapoints/__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().
  warnings.warn(_BETA_TRANSFORMS_WARNING)
/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torchvision/transforms/v2/__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().
  warnings.warn(_BETA_TRANSFORMS_WARNING)
Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]Loading checkpoint shards:  14%|█▍        | 1/7 [00:00<00:03,  1.75it/s]Loading checkpoint shards:  29%|██▊       | 2/7 [00:01<00:02,  1.97it/s]Loading checkpoint shards:  43%|████▎     | 3/7 [00:01<00:01,  2.11it/s]Loading checkpoint shards:  57%|█████▋    | 4/7 [00:01<00:01,  2.30it/s]Loading checkpoint shards:  71%|███████▏  | 5/7 [00:02<00:00,  2.42it/s]Loading checkpoint shards:  86%|████████▌ | 6/7 [00:02<00:00,  2.53it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:02<00:00,  2.73it/s]Loading checkpoint shards: 100%|██████████| 7/7 [00:02<00:00,  2.43it/s]
/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
load clip successfully...
Loaded class indices from ./imagenet_class_indices.pkl
get supportng set ...
get samples for each class:   0%|          | 0/100 [00:00<?, ?it/s]get samples for each class:   1%|          | 1/100 [00:00<00:31,  3.18it/s]get samples for each class:   2%|▏         | 2/100 [00:00<00:29,  3.37it/s]get samples for each class:   3%|▎         | 3/100 [00:00<00:26,  3.68it/s]get samples for each class:   4%|▍         | 4/100 [00:01<00:25,  3.82it/s]get samples for each class:   5%|▌         | 5/100 [00:01<00:26,  3.57it/s]get samples for each class:   6%|▌         | 6/100 [00:01<00:27,  3.39it/s]get samples for each class:   7%|▋         | 7/100 [00:02<00:29,  3.11it/s]get samples for each class:   8%|▊         | 8/100 [00:02<00:31,  2.95it/s]get samples for each class:   9%|▉         | 9/100 [00:02<00:31,  2.92it/s]get samples for each class:  10%|█         | 10/100 [00:03<00:31,  2.83it/s]get samples for each class:  11%|█         | 11/100 [00:03<00:29,  3.03it/s]get samples for each class:  12%|█▏        | 12/100 [00:03<00:27,  3.18it/s]get samples for each class:  13%|█▎        | 13/100 [00:04<00:26,  3.28it/s]get samples for each class:  14%|█▍        | 14/100 [00:04<00:26,  3.28it/s]get samples for each class:  15%|█▌        | 15/100 [00:04<00:25,  3.27it/s]get samples for each class:  16%|█▌        | 16/100 [00:04<00:25,  3.28it/s]get samples for each class:  17%|█▋        | 17/100 [00:05<00:24,  3.40it/s]get samples for each class:  18%|█▊        | 18/100 [00:05<00:24,  3.34it/s]get samples for each class:  19%|█▉        | 19/100 [00:05<00:24,  3.30it/s]get samples for each class:  20%|██        | 20/100 [00:06<00:23,  3.38it/s]get samples for each class:  21%|██        | 21/100 [00:06<00:23,  3.42it/s]get samples for each class:  22%|██▏       | 22/100 [00:06<00:22,  3.52it/s]get samples for each class:  23%|██▎       | 23/100 [00:06<00:22,  3.50it/s]get samples for each class:  24%|██▍       | 24/100 [00:07<00:22,  3.44it/s]get samples for each class:  25%|██▌       | 25/100 [00:07<00:22,  3.38it/s]get samples for each class:  26%|██▌       | 26/100 [00:07<00:22,  3.31it/s]get samples for each class:  27%|██▋       | 27/100 [00:08<00:20,  3.48it/s]get samples for each class:  28%|██▊       | 28/100 [00:08<00:21,  3.35it/s]get samples for each class:  29%|██▉       | 29/100 [00:08<00:20,  3.40it/s]get samples for each class:  30%|███       | 30/100 [00:08<00:18,  3.80it/s]get samples for each class:  31%|███       | 31/100 [00:09<00:19,  3.46it/s]get samples for each class:  32%|███▏      | 32/100 [00:09<00:20,  3.34it/s]get samples for each class:  33%|███▎      | 33/100 [00:09<00:20,  3.19it/s]get samples for each class:  34%|███▍      | 34/100 [00:10<00:20,  3.25it/s]get samples for each class:  35%|███▌      | 35/100 [00:10<00:20,  3.23it/s]get samples for each class:  36%|███▌      | 36/100 [00:10<00:20,  3.08it/s]get samples for each class:  37%|███▋      | 37/100 [00:11<00:20,  3.15it/s]get samples for each class:  38%|███▊      | 38/100 [00:11<00:25,  2.43it/s]get samples for each class:  39%|███▉      | 39/100 [00:12<00:22,  2.69it/s]get samples for each class:  40%|████      | 40/100 [00:12<00:21,  2.73it/s]get samples for each class:  41%|████      | 41/100 [00:12<00:20,  2.86it/s]get samples for each class:  42%|████▏     | 42/100 [00:13<00:19,  2.99it/s]get samples for each class:  43%|████▎     | 43/100 [00:13<00:18,  3.07it/s]get samples for each class:  44%|████▍     | 44/100 [00:13<00:16,  3.31it/s]get samples for each class:  45%|████▌     | 45/100 [00:13<00:16,  3.30it/s]get samples for each class:  46%|████▌     | 46/100 [00:14<00:16,  3.22it/s]get samples for each class:  47%|████▋     | 47/100 [00:14<00:16,  3.22it/s]get samples for each class:  48%|████▊     | 48/100 [00:14<00:15,  3.38it/s]get samples for each class:  49%|████▉     | 49/100 [00:15<00:15,  3.21it/s]get samples for each class:  50%|█████     | 50/100 [00:15<00:16,  2.98it/s]get samples for each class:  51%|█████     | 51/100 [00:15<00:16,  2.92it/s]get samples for each class:  52%|█████▏    | 52/100 [00:16<00:15,  3.08it/s]get samples for each class:  53%|█████▎    | 53/100 [00:16<00:15,  3.00it/s]get samples for each class:  54%|█████▍    | 54/100 [00:17<00:17,  2.66it/s]get samples for each class:  55%|█████▌    | 55/100 [00:17<00:16,  2.65it/s]get samples for each class:  56%|█████▌    | 56/100 [00:17<00:16,  2.71it/s]get samples for each class:  57%|█████▋    | 57/100 [00:18<00:15,  2.85it/s]get samples for each class:  58%|█████▊    | 58/100 [00:18<00:15,  2.80it/s]get samples for each class:  59%|█████▉    | 59/100 [00:18<00:14,  2.80it/s]get samples for each class:  60%|██████    | 60/100 [00:19<00:12,  3.13it/s]get samples for each class:  61%|██████    | 61/100 [00:19<00:12,  3.21it/s]get samples for each class:  62%|██████▏   | 62/100 [00:19<00:12,  3.07it/s]get samples for each class:  63%|██████▎   | 63/100 [00:20<00:12,  3.01it/s]get samples for each class:  64%|██████▍   | 64/100 [00:20<00:10,  3.29it/s]get samples for each class:  65%|██████▌   | 65/100 [00:20<00:12,  2.75it/s]get samples for each class:  66%|██████▌   | 66/100 [00:21<00:11,  2.88it/s]get samples for each class:  67%|██████▋   | 67/100 [00:21<00:10,  3.03it/s]get samples for each class:  68%|██████▊   | 68/100 [00:21<00:10,  2.93it/s]get samples for each class:  69%|██████▉   | 69/100 [00:22<00:09,  3.18it/s]get samples for each class:  70%|███████   | 70/100 [00:22<00:09,  3.10it/s]get samples for each class:  71%|███████   | 71/100 [00:22<00:09,  3.14it/s]get samples for each class:  72%|███████▏  | 72/100 [00:22<00:08,  3.19it/s]get samples for each class:  73%|███████▎  | 73/100 [00:23<00:08,  3.25it/s]get samples for each class:  74%|███████▍  | 74/100 [00:23<00:07,  3.49it/s]get samples for each class:  75%|███████▌  | 75/100 [00:23<00:07,  3.36it/s]get samples for each class:  76%|███████▌  | 76/100 [00:24<00:06,  3.48it/s]get samples for each class:  77%|███████▋  | 77/100 [00:24<00:06,  3.30it/s]get samples for each class:  78%|███████▊  | 78/100 [00:24<00:06,  3.29it/s]get samples for each class:  79%|███████▉  | 79/100 [00:24<00:05,  3.62it/s]get samples for each class:  80%|████████  | 80/100 [00:25<00:05,  3.47it/s]get samples for each class:  81%|████████  | 81/100 [00:25<00:04,  3.82it/s]get samples for each class:  82%|████████▏ | 82/100 [00:25<00:04,  3.62it/s]get samples for each class:  83%|████████▎ | 83/100 [00:26<00:05,  3.38it/s]get samples for each class:  84%|████████▍ | 84/100 [00:26<00:04,  3.27it/s]get samples for each class:  85%|████████▌ | 85/100 [00:26<00:04,  3.12it/s]get samples for each class:  86%|████████▌ | 86/100 [00:27<00:04,  3.06it/s]get samples for each class:  87%|████████▋ | 87/100 [00:27<00:04,  3.08it/s]get samples for each class:  88%|████████▊ | 88/100 [00:27<00:03,  3.14it/s]get samples for each class:  89%|████████▉ | 89/100 [00:28<00:03,  3.17it/s]get samples for each class:  90%|█████████ | 90/100 [00:28<00:03,  3.29it/s]get samples for each class:  91%|█████████ | 91/100 [00:28<00:02,  3.23it/s]get samples for each class:  92%|█████████▏| 92/100 [00:28<00:02,  3.28it/s]get samples for each class:  93%|█████████▎| 93/100 [00:29<00:02,  3.07it/s]get samples for each class:  94%|█████████▍| 94/100 [00:29<00:01,  3.14it/s]get samples for each class:  95%|█████████▌| 95/100 [00:29<00:01,  3.35it/s]get samples for each class:  96%|█████████▌| 96/100 [00:30<00:01,  3.45it/s]get samples for each class:  97%|█████████▋| 97/100 [00:30<00:00,  3.25it/s]get samples for each class:  98%|█████████▊| 98/100 [00:30<00:00,  3.24it/s]get samples for each class:  99%|█████████▉| 99/100 [00:31<00:00,  3.29it/s]get samples for each class: 100%|██████████| 100/100 [00:31<00:00,  3.04it/s]get samples for each class: 100%|██████████| 100/100 [00:31<00:00,  3.17it/s]
Support set size: 1000
Preprocess Supporting set...:   0%|          | 0/1000 [00:00<?, ?it/s]Preprocess Supporting set...: 100%|██████████| 1000/1000 [00:00<00:00, 505886.38it/s]
Inference ImageNet...:   0%|          | 0/5000 [00:00<?, ?it/s]IndexError at position 4 with ct[i]=719 and token=719: tuple index out of range
IndexError at position 4 with ct[i]=719 and token=719: tuple index out of range
IndexError at position 4 with ct[i]=719 and token=719: tuple index out of range
IndexError at position 4 with ct[i]=20128 and token=20128: tuple index out of range
IndexError at position 4 with ct[i]=18843 and token=18843: tuple index out of range
IndexError at position 4 with ct[i]=13982 and token=13982: tuple index out of range
IndexError at position 4 with ct[i]=4427 and token=4427: tuple index out of range
IndexError at position 4 with ct[i]=4427 and token=4427: tuple index out of range
IndexError at position 4 with ct[i]=28714 and token=28714: tuple index out of range
IndexError at position 4 with ct[i]=9617 and token=9617: tuple index out of range
IndexError at position 4 with ct[i]=28721 and token=28721: tuple index out of range
IndexError at position 4 with ct[i]=261 and token=261: tuple index out of range
IndexError at position 4 with ct[i]=261 and token=261: tuple index out of range
IndexError at position 4 with ct[i]=291 and token=291: tuple index out of range
IndexError at position 4 with ct[i]=291 and token=291: tuple index out of range
IndexError at position 4 with ct[i]=606 and token=606: tuple index out of range
IndexError at position 4 with ct[i]=2238 and token=2238: tuple index out of range
IndexError at position 4 with ct[i]=388 and token=388: tuple index out of range
IndexError at position 4 with ct[i]=485 and token=485: tuple index out of range
IndexError at position 4 with ct[i]=14640 and token=14640: tuple index out of range
IndexError at position 4 with ct[i]=14640 and token=14640: tuple index out of range
IndexError at position 4 with ct[i]=266 and token=266: tuple index out of range
IndexError at position 4 with ct[i]=19114 and token=19114: tuple index out of range
IndexError at position 4 with ct[i]=2599 and token=2599: tuple index out of range
IndexError at position 4 with ct[i]=606 and token=606: tuple index out of range
IndexError at position 4 with ct[i]=28733 and token=28733: tuple index out of range
IndexError at position 4 with ct[i]=6385 and token=6385: tuple index out of range
IndexError at position 4 with ct[i]=16624 and token=16624: tuple index out of range
IndexError at position 4 with ct[i]=408 and token=408: tuple index out of range
IndexError at position 4 with ct[i]=408 and token=408: tuple index out of range
IndexError at position 4 with ct[i]=570 and token=570: tuple index out of range
IndexError at position 4 with ct[i]=1184 and token=1184: tuple index out of range
IndexError at position 4 with ct[i]=1184 and token=1184: tuple index out of range
IndexError at position 4 with ct[i]=336 and token=336: tuple index out of range
IndexError at position 4 with ct[i]=331 and token=331: tuple index out of range
IndexError at position 4 with ct[i]=518 and token=518: tuple index out of range
IndexError at position 4 with ct[i]=319 and token=319: tuple index out of range
IndexError at position 4 with ct[i]=28714 and token=28714: tuple index out of range
IndexError at position 4 with ct[i]=15543 and token=15543: tuple index out of range
IndexError at position 4 with ct[i]=28733 and token=28733: tuple index out of range
IndexError at position 4 with ct[i]=299 and token=299: tuple index out of range
IndexError at position 4 with ct[i]=795 and token=795: tuple index out of range
IndexError at position 4 with ct[i]=13072 and token=13072: tuple index out of range
Inference ImageNet...:   0%|          | 1/5000 [00:01<1:59:00,  1.43s/it]Inference ImageNet...:   0%|          | 2/5000 [00:02<2:05:36,  1.51s/it]IndexError at position 9 with ct[i]=28709 and token=28709: tuple index out of range
Inference ImageNet...:   0%|          | 3/5000 [00:04<2:08:18,  1.54s/it]Inference ImageNet...:   0%|          | 4/5000 [00:05<1:47:53,  1.30s/it]Inference ImageNet...:   0%|          | 5/5000 [00:06<1:53:25,  1.36s/it]Inference ImageNet...:   0%|          | 6/5000 [00:07<1:43:37,  1.25s/it]Inference ImageNet...:   0%|          | 7/5000 [00:08<1:28:58,  1.07s/it]Inference ImageNet...:   0%|          | 8/5000 [00:09<1:27:33,  1.05s/it]Inference ImageNet...:   0%|          | 9/5000 [00:10<1:24:37,  1.02s/it]Inference ImageNet...:   0%|          | 10/5000 [00:11<1:30:16,  1.09s/it]IndexError at position 5 with ct[i]=302 and token=302: tuple index out of range
IndexError at position 5 with ct[i]=3525 and token=3525: tuple index out of range
IndexError at position 5 with ct[i]=3525 and token=3525: tuple index out of range
IndexError at position 5 with ct[i]=28709 and token=28709: tuple index out of range
IndexError at position 5 with ct[i]=14345 and token=14345: tuple index out of range
IndexError at position 5 with ct[i]=606 and token=606: tuple index out of range
IndexError at position 5 with ct[i]=546 and token=546: tuple index out of range
IndexError at position 5 with ct[i]=286 and token=286: tuple index out of range
IndexError at position 5 with ct[i]=28711 and token=28711: tuple index out of range
IndexError at position 5 with ct[i]=271 and token=271: tuple index out of range
IndexError at position 5 with ct[i]=286 and token=286: tuple index out of range
IndexError at position 5 with ct[i]=1061 and token=1061: tuple index out of range
IndexError at position 5 with ct[i]=1061 and token=1061: tuple index out of range
IndexError at position 5 with ct[i]=331 and token=331: tuple index out of range
IndexError at position 5 with ct[i]=518 and token=518: tuple index out of range
IndexError at position 5 with ct[i]=940 and token=940: tuple index out of range
IndexError at position 5 with ct[i]=961 and token=961: tuple index out of range
IndexError at position 5 with ct[i]=3051 and token=3051: tuple index out of range
Inference ImageNet...:   0%|          | 11/5000 [00:12<1:14:37,  1.11it/s]Inference ImageNet...:   0%|          | 12/5000 [00:13<1:30:26,  1.09s/it]Inference ImageNet...:   0%|          | 13/5000 [00:14<1:27:48,  1.06s/it]Inference ImageNet...:   0%|          | 14/5000 [00:16<1:39:45,  1.20s/it]Inference ImageNet...:   0%|          | 15/5000 [00:17<1:46:50,  1.29s/it]IndexError at position 9 with ct[i]=28709 and token=28709: tuple index out of range
Inference ImageNet...:   0%|          | 16/5000 [00:18<1:37:08,  1.17s/it]Inference ImageNet...:   0%|          | 17/5000 [00:19<1:30:55,  1.09s/it]Inference ImageNet...:   0%|          | 17/5000 [00:19<1:37:25,  1.17s/it]
Traceback (most recent call last):
  File "/data/chy/online/ImageNet/main.py", line 106, in <module>
    results, predictions = inferencer.run()
  File "/data/chy/online/ImageNet/inferencers.py", line 927, in run
    self.inference_batch(batch_samples)
  File "/data/chy/online/ImageNet/inferencers.py", line 785, in inference_batch
    self.evaluate_batch_on_idev2(batch_samples)
  File "/data/chy/online/ImageNet/inferencers.py", line 830, in evaluate_batch_on_idev2
    outputs = self.model.generate(**inputs, bad_words_ids=BAD_WORDS_IDS,min_new_tokens=1, max_new_tokens=20,num_beams=1,
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/transformers/generation/utils.py", line 2215, in generate
    result = self._sample(
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/transformers/generation/utils.py", line 3206, in _sample
    outputs = self(**model_inputs, return_dict=True)
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/transformers/models/idefics2/modeling_idefics2.py", line 1624, in forward
    outputs = self.model(
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/transformers/models/idefics2/modeling_idefics2.py", line 1423, in forward
    image_hidden_states = self.vision_model(
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/transformers/models/idefics2/modeling_idefics2.py", line 706, in forward
    encoder_outputs = self.encoder(
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/transformers/models/idefics2/modeling_idefics2.py", line 554, in forward
    layer_outputs = encoder_layer(
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/transformers/models/idefics2/modeling_idefics2.py", line 466, in forward
    hidden_states, attn_weights = self.self_attn(
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/transformers/models/idefics2/modeling_idefics2.py", line 250, in forward
    attn_weights = nn.functional.softmax(attn_weights, dim=-1, dtype=torch.float32).to(query_states.dtype)
  File "/home/chy63/.conda/envs/openflamingo/lib/python3.9/site-packages/torch/nn/functional.py", line 1845, in softmax
    ret = input.softmax(dim, dtype=dtype)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 3.23 GiB (GPU 0; 23.68 GiB total capacity; 20.89 GiB already allocated; 2.01 GiB free; 21.35 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
